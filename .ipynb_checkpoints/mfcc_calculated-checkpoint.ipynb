{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "from io import StringIO\n",
    "import warnings\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if os.path.exists(\"../input/birdsong-recognition/test_audio/\"):\n",
    "    n_epochs=200\n",
    "    fc=None\n",
    "else:\n",
    "    n_epochs=2\n",
    "    fc=2\n",
    "\n",
    "prob_cutoff = 0.5\n",
    "\n",
    "prepared_test_str = \"\"\"row_id,site,audio_id,seconds\n",
    "bulori/XC128942,bulori/XC128942,bulori/XC128942,5\n",
    "bulori/XC170988,bulori/XC170988,bulori/XC170988,5\n",
    "normoc/XC54018,normoc/XC54018,normoc/XC54018,5\n",
    "normoc/XC62791,normoc/XC62791,normoc/XC62791,5\n",
    "herthr/XC53784,herthr/XC53784,herthr/XC53784,5\n",
    "herthr/XC119596,herthr/XC119596,herthr/XC119596,5\n",
    "brnthr/XC31308,brnthr/XC31308,brnthr/XC31308,5\n",
    "brnthr/XC53695,brnthr/XC53695,brnthr/XC53695,5\n",
    "vesspa/XC17095,vesspa/XC17095,vesspa/XC17095,5\n",
    "vesspa/XC17096,vesspa/XC17096,vesspa/XC17096,5\n",
    "solsan/XC17025,solsan/XC17025,solsan/XC17025,5\n",
    "norfli/XC11578,norfli/XC11578,norfli/XC11578,5\n",
    "lesnig/XC27724,lesnig/XC27724,lesnig/XC27724,5\n",
    "grycat/XC31058,grycat/XC31058,grycat/XC31058,5\n",
    "eastow/XC53188,eastow/XC53188,eastow/XC53188,5\n",
    "aldfly/XC2628,aldfly/XC2628,aldfly/XC2628,5\n",
    "ameavo/XC99571,ameavo/XC99571,ameavo/XC99571,5\n",
    "amebit/XC127371,amebit/XC127371,amebit/XC127371,5\n",
    "amecro/XC51410,amecro/XC51410,amecro/XC51410,5\n",
    "amegfi/XC17120,amegfi/XC17120,amegfi/XC17120,5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_audio(path):\n",
    "    signal, blah = librosa.load(path, sr=22050)\n",
    "    \n",
    "    if len(signal.shape)==1:\n",
    "        y = signal\n",
    "    else:\n",
    "        y = np.average(signal, axis=1)\n",
    "    \n",
    "    return signal\n",
    "    \n",
    "\n",
    "def getBirdMfcc(bird, n_mfcc=50, filecount=None):\n",
    "    birddirectory = \"data/mfcc_50/\" + bird\n",
    "    files = os.listdir(birddirectory)\n",
    "    \n",
    "    if filecount!=None:\n",
    "        files = files[:filecount]\n",
    "    \n",
    "    mfcc = []\n",
    "    for fileName in files:\n",
    "        file = os.path.join(birddirectory + \"/\", fileName)\n",
    "        print(\"reading file: {}\".format(file))\n",
    "        try:\n",
    "            new_y = load_test_audio(file)\n",
    "        except:\n",
    "            continue\n",
    "        if len(new_y)==0:\n",
    "            continue\n",
    "        new_mfcc = librosa.feature.mfcc(n_mfcc=50, y=new_y, sr=22050)\n",
    "        mfcc.append(new_mfcc)\n",
    "        del(new_y)\n",
    "    gc.collect()\n",
    "    mfcc = np.concatenate(mfcc,axis=1).T\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(sparse=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_directory = '../input/mfcc-50/'\n",
    "birds = [\"bulori\", \"normoc\", \"herthr\", \"brnthr\", \"vesspa\",    'aldfly', 'ameavo', 'amebit', 'amecro', 'amegfi']\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "le = LabelEncoder()\n",
    "\n",
    "features = np.array(birds[:5])\n",
    "fint = le.fit_transform(features).reshape(len(features),1)\n",
    "\n",
    "ohe.fit(fint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file: ../input/birdsong-recognition/train_audio/bulori/XC183352.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/bulori/XC260196.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/normoc/XC374601.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/normoc/XC309813.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/herthr/XC211200.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/herthr/XC323240.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/brnthr/XC136053.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/brnthr/XC174538.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/vesspa/XC140478.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/vesspa/XC297169.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/aldfly/XC135459.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/aldfly/XC189263.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/ameavo/XC139829.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/ameavo/XC304446.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/amebit/XC184882.mp3\n",
      "reading file: ../input/birdsong-recognition/train_audio/amebit/XC370240.mp3\n"
     ]
    }
   ],
   "source": [
    "dataMap = {}\n",
    "testMap = {}\n",
    "\n",
    "for bird in birds:\n",
    "    bird_mfcc = getBirdMfcc(bird, filecount=fc)\n",
    "    train_samples = int(0.7*bird_mfcc.shape[0])\n",
    "    test_samples = -1*int(0.3*bird_mfcc.shape[0])\n",
    "    dataMap[bird] = bird_mfcc[:train_samples,]\n",
    "    testMap[bird] = bird_mfcc[test_samples:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(None, 50)))\n",
    "model.add(Bidirectional(LSTM(10, return_sequences=True)))\n",
    "model.add(Dense(5, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    while True:\n",
    "        sequence_length = 215\n",
    "        \n",
    "        xarr = []\n",
    "        yarr = []\n",
    "        for k,v in dataMap.items():\n",
    "            nsamples = v.shape[0]\n",
    "            samples = np.random.randint(0,nsamples-sequence_length+1,size=100)\n",
    "            try:\n",
    "                birdohe = ohe.transform(le.transform([k]).reshape(1,1))\n",
    "            except:\n",
    "                birdohe = np.array([[0, 0, 0, 0, 0]])\n",
    "            for sample in samples:\n",
    "                xarr.append(v[sample:sample+sequence_length,:].reshape(1,sequence_length,50))\n",
    "                yarr.append(np.tile(birdohe,(sequence_length,1)).reshape(1,sequence_length,5))\n",
    "        x_train = np.concatenate(xarr)\n",
    "        y_train = np.concatenate(yarr)\n",
    "        x_train, y_train = shuffle(x_train, y_train)\n",
    "        yield x_train, y_train\n",
    "\n",
    "def test_generator():\n",
    "    sequence_length = 215\n",
    "\n",
    "    xarr = []\n",
    "    yarr = []\n",
    "    for k,v in testMap.items():\n",
    "        nsamples = v.shape[0]\n",
    "        samples = np.random.randint(0,nsamples-sequence_length+1,size=1000)\n",
    "        try:\n",
    "            birdohe = ohe.transform(le.transform([k]).reshape(1,1))\n",
    "        except:\n",
    "            birdohe = np.array([[0, 0, 0, 0, 0]])\n",
    "        for sample in samples:\n",
    "            xarr.append(v[sample:sample+sequence_length,:].reshape(1,sequence_length,50))\n",
    "            yarr.append(np.tile(birdohe,(sequence_length,1)).reshape(1,sequence_length,5))\n",
    "    x_train = np.concatenate(xarr)\n",
    "    y_train = np.concatenate(yarr)\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    return x_train, y_train\n",
    "\n",
    "# x,y = train_generator()\n",
    "history = model.fit_generator(train_generator(), steps_per_epoch=30, epochs=n_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()\n",
    "\n",
    "x_test, y_test = test_generator()\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"../input/birdsong-recognition/test_audio/\"):\n",
    "    test_dir = \"../input/birdsong-recognition/test_audio/\"\n",
    "    testtable = pd.read_csv(\"../input/birdsong-recognition/test.csv\")\n",
    "else:\n",
    "    test_dir = \"../input/birdsong-recognition/train_audio/\"\n",
    "    testtable = pd.read_csv(StringIO(prepared_test_str))\n",
    "\n",
    "\n",
    "def load_test_clip(signal, start_time, duration=5):\n",
    "    sr=22050\n",
    "    maxl = len(signal)\n",
    "    \n",
    "    if duration!=None:\n",
    "        y = signal[max(0,int(start_time)*22050):min(int(start_time+duration)*22050,maxl)]\n",
    "    else:\n",
    "        y = signal[max(0,start_time*22050):]\n",
    "    \n",
    "    mfcc_feat = librosa.feature.mfcc(n_mfcc=50, y=y, sr=22050)\n",
    "    return mfcc_feat.T\n",
    "\n",
    "def make_prediction(sound_clip):\n",
    "    predidx = [i for i,each in enumerate(make_probabilities(sound_clip)) if each>prob_cutoff]\n",
    "    if len(predidx)==0:\n",
    "        predbirds = \"nocall\"\n",
    "    else:\n",
    "        predbirds = \" \".join(list(le.inverse_transform(predidx)))\n",
    "    \n",
    "    return predbirds\n",
    "\n",
    "def make_probabilities(sound_clip):\n",
    "    mfccdim = sound_clip.shape\n",
    "    sound_clip = sound_clip.reshape(1,mfccdim[0],mfccdim[1])\n",
    "    \n",
    "    pred = model.predict(sound_clip).reshape(mfccdim[0],5)\n",
    "    \n",
    "    return np.mean(pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_info = testtable.sort_values(\"audio_id\")\n",
    "\n",
    "preds = []\n",
    "sound_read = \"\"\n",
    "for index, row in test_info.iterrows():\n",
    "    # Get test row information\n",
    "    site = row['site']\n",
    "    try:\n",
    "        start_time = row['seconds'] - 5\n",
    "    except:\n",
    "        start_time = 0\n",
    "    row_id = row['row_id']\n",
    "    audio_id = row['audio_id']\n",
    "\n",
    "    try:\n",
    "        if sound_read != audio_id:\n",
    "            sound_audio = load_test_audio(test_dir + audio_id + '.mp3')\n",
    "            sound_read = audio_id\n",
    "    except:\n",
    "        print(\"exception\")\n",
    "        pred = \"nocall\"\n",
    "        preds.append(pred)\n",
    "        continue\n",
    "        \n",
    "    if site == 'site_3':\n",
    "        sound_clip = load_test_clip(sound_audio, 0, duration=None)\n",
    "    else:\n",
    "        sound_clip = load_test_clip(sound_audio, start_time)\n",
    "            \n",
    "    \n",
    "    pred = make_prediction(sound_clip)\n",
    "    preds.append(pred)\n",
    "    \n",
    "testtable = test_info.sort_index()\n",
    "\n",
    "test_submission = testtable.drop(['site', 'audio_id', 'seconds'], axis = 1) \n",
    "test_submission['birds'] = preds\n",
    "\n",
    "test_submission.to_csv('submission.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(test_submission.head(20))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
