{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfcc_directory = 'data/mfcc_50/'\n",
    "picklefiles = os.listdir(mfcc_directory)[:5]\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "le = LabelEncoder()\n",
    "\n",
    "features = np.array([pickle.split(\".\")[0] for pickle in picklefiles])\n",
    "fint = le.fit_transform(features).reshape(len(features),1)\n",
    "\n",
    "ohe.fit(fint)\n",
    "\n",
    "dataMap = {}\n",
    "\n",
    "for picklefile in picklefiles:\n",
    "    birdName = picklefile.split(\".\")[0]\n",
    "    fullPath = os.path.join(mfcc_directory,picklefile)\n",
    "    dataMap[birdName] = pickle.load(open(fullPath,'rb')).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(None, 50)))\n",
    "model.add(Bidirectional(LSTM(10, return_sequences=True)))\n",
    "model.add(Dense(5, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 152s 5s/step - loss: 0.0355\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 144s 5s/step - loss: 0.0331\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 161s 5s/step - loss: 0.0369\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 158s 5s/step - loss: 0.0379\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 171s 6s/step - loss: 0.0360\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 162s 5s/step - loss: 0.0370\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 155s 5s/step - loss: 0.0356\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 159s 5s/step - loss: 0.0351\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 159s 5s/step - loss: 0.0333\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 164s 5s/step - loss: 0.0339\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 161s 5s/step - loss: 0.0337\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 156s 5s/step - loss: 0.0331\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 165s 6s/step - loss: 0.0339\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 172s 6s/step - loss: 0.0310\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 162s 5s/step - loss: 0.0310\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 163s 5s/step - loss: 0.0323\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 168s 6s/step - loss: 0.0317\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 172s 6s/step - loss: 0.0353\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 120s 4s/step - loss: 0.0325\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 66s 2s/step - loss: 0.0334\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 64s 2s/step - loss: 0.0296\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 65s 2s/step - loss: 0.0314\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 63s 2s/step - loss: 0.0315\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0308\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.0289\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0300\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0297\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0311\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0298\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.0293\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.0322\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.0293\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0293\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 64s 2s/step - loss: 0.0307\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.0298\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 66s 2s/step - loss: 0.0283\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 63s 2s/step - loss: 0.0281\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0283\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0294\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.0285\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.0274\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.0285\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0280\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.0265\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0256\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.0282\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 63s 2s/step - loss: 0.0274\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 61s 2s/step - loss: 0.0266\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0254\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 62s 2s/step - loss: 0.0264\n"
     ]
    }
   ],
   "source": [
    "def train_generator():\n",
    "    while True:\n",
    "        sequence_length = 115\n",
    "        \n",
    "        xarr = []\n",
    "        yarr = []\n",
    "        for k,v in dataMap.items():\n",
    "            nsamples = v.shape[0]\n",
    "            samples = np.random.randint(0,nsamples-sequence_length+1,size=100)\n",
    "            birdohe = ohe.transform(le.transform([k]).reshape(1,1))\n",
    "            for sample in samples:\n",
    "                xarr.append(v[sample:sample+sequence_length,:].reshape(1,sequence_length,50))\n",
    "                yarr.append(np.tile(birdohe,(sequence_length,1)).reshape(1,sequence_length,5))\n",
    "        x_train = np.concatenate(xarr)\n",
    "        y_train = np.concatenate(yarr)\n",
    "        \n",
    "#         x_train = np.random.random((1000, sequence_length, 5))\n",
    "#         # y_train will depend on past 5 timesteps of x\n",
    "#         y_train = x_train[:, :, 0]\n",
    "#         for i in range(1, 5):\n",
    "#             y_train[:, i:] += x_train[:, :-i, i]\n",
    "#         y_train = to_categorical(y_train > 2.5)\n",
    "        yield x_train, y_train\n",
    "\n",
    "# x,y = train_generator()\n",
    "history = model.fit_generator(train_generator(), steps_per_epoch=30, epochs=50, verbose=1)\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected bidirectional_31_input to have shape (115, 50) but got array with shape (50, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-1f8c5eede3fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\karamvenkatsaigiridh\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              'argument.')\n\u001b[0;32m   1148\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\karamvenkatsaigiridh\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\karamvenkatsaigiridh\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected bidirectional_31_input to have shape (115, 50) but got array with shape (50, 50)"
     ]
    }
   ],
   "source": [
    "sequence_length = 50\n",
    "\n",
    "xarr = []\n",
    "yarr = []\n",
    "for k,v in dataMap.items():\n",
    "    nsamples = v.shape[0]\n",
    "    samples = np.random.randint(0,nsamples-sequence_length+1,size=1)\n",
    "    birdohe = np.array([0,0,0,0,0])\n",
    "    for sample in samples:\n",
    "        xarr.append(v[sample:sample+sequence_length,:].reshape(1,sequence_length,50))\n",
    "        yarr.append(np.tile(birdohe,(sequence_length,1)).reshape(1,sequence_length,5))\n",
    "\n",
    "x_train = np.concatenate(xarr)\n",
    "y_train = np.concatenate(yarr)\n",
    "\n",
    "model.predict(x_train[:2,:,:])[:,:50,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfcc_directory = 'data/mfcc_50/'\n",
    "picklefiles = os.listdir(mfcc_directory)[-5:]\n",
    "\n",
    "dataMap2 = {}\n",
    "\n",
    "for picklefile in picklefiles:\n",
    "    birdName = picklefile.split(\".\")[0]\n",
    "    fullPath = os.path.join(mfcc_directory,picklefile)\n",
    "    dataMap2[birdName] = pickle.load(open(fullPath,'rb')).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
